!! DataFrame by example

In this chapter, I will guide you through the complete functionality of the DataFrame project by showing examples of how each of those features can be used. This is a documentation of DataFrame written in a form of storytelling with data.

!!! Weather dataset
@weatherDataset

For the demonstrational purposes, I have designed a simple dataset of meteorological observations. Imagine that to study the weather in certain area, you are collecting data by measuring the temperature and logging the type of precipitation (rain, snow etc.) every 20 minutes. The initial table contains only 5 observations (rows) and 3 features (columns): ==temperature==, ==precipitation==, and ==type==. You can see this table in the top left of Figure *@weatherDataFrame*. As we progress through this chapter, we will be modifying, adding, and removing rows and columns of this dataset. Two additional columns that we will add are ==humidity== and ==wind==.

+Weather data frame and two data series extracted from it: homogeneous series of temperature column and heterogeneous series of the third row>Images/weather.png|width=80|label=weatherDataFrame+


!!! What are data frames and data series

Before moving forward, you need to get a better understanding of the basic data structures that we use to model tabular data. In this section, I will explain the theoretical aspects of data frame and data series collections.

Data frame is a table of data. Similar to Excel spreadsheet or a relational database, but implemented as a collection that can be stored in a variable, such as ==Array== or ==Dictionary==. This greatly simplifies the data analysis workflow. Because, to answer questions such as ''"What was the temperature at 01:30?"'' or ''"What is the average humidity when it snows?"'', we do not need to set up a whole database. Instead, we can simply load our data into a variable and query it - all in three lines of code (you will learn how to do it by reading the rest of this chapter):

[[[
weather := DataFrame readFromCsv: 'weather.csv'.

"Question 1"
weather at: 01:30 at: #temperature.

"Question 2"
(weather group: #temperature by: #type aggregateUsing: #average) at: #snow.
]]]

In the top left of Figure *@weatherDataFrame*, you can see our weather dataset represented as a data frame. It contains three columns: ==Float== column of temperatures, ==Boolean== column which tells you whether or not there were any precipitations, and a ==String== column that specifies the type of precipitation. Data types of columns are represented with different background colors.



It is common to think of rows as observations and columns as features. Therefore, columns are usually homogeneous - they contain values of a same data type, and rows can be heterogeneous - contain values of different types, such as ==Integer==, ==Float==, ==Boolean==, ==String==, etc.

Each row or column can be extracted as a ==DataSeries== object - a dictionary of key-value pairs with a name. The keys of a row are the column nemes and for a column there are the row names of a data frame. This means that, by having those keys and a name, every individual row or column contains all the information that is needed to identify its precise location in a data frame, as well as the meaning of each value. As a result, data series is much more interpretable than a simple array of values, which allows us to construct more meaningful queries while analysing the dataset. We can add two series together, multiply them by a number, calculate the variance or standard deviation of a series, select elements that satisfy a certain condition, and do many other things that will be described in the following sections.

You can see the example of two data series in the top right and bottom of Figure *@weatherDataFrame*. Column ==temperature== is a homogeneous ==Float== data series and the row ==01:50== is a heterogeneous series containing different types of values.

In the following section I will show you how to create a weather data frame and analyse it in Pharo. But first you need to install DataFrame v2.0 and make sure that all its tests are passing.

!!! Installation

To install DataFrame, go to the Playground (Ctrl\+O\+W) in your fresh Pharo image and execute the following Metacello script (select it and press Do-it button or Ctrl\+D):

[[[language=smalltalk
Metacello new
  baseline: 'DataFrame';
  repository: 'github://PolyMathOrg/DataFrame/src';
  load.
]]]

In all keyboard shortcuts mentioned in this booklet the ''Ctrl'' key is for Windows and Linux. On Mac OS, use ''Cmd'' instead.

!!!! Running the tests

First thing you should do after installing DataFrame is open the DataFrame-Tests package in Test Runner (Ctrl\+O\+U) or System Browser (Ctrl\+O\+B) and make sure that all tests are passing. DataFrame v2.0 is tested with 301 unit tests which provide 90\% code coverage. If you see some failing tests, please go to the DataFrame repository on GitHub and open a related issue.

!!! Creating a data series
@secCreatingDataSeries

==DataSeries== behaves like an ==OrderedDictionary==. You can create it by providing keys, values, and a name:

[[[
DataSeries
  withKeys: (#('01:10' '01:30' '01:50' '02:10' '02:30') collect: #asTime)
  values: #(2.4 0.5 -1.2 -2.3 3.2)
  name: #temperature.
]]]

This creates the first column of our weather data frame.

| |!temperature
|!1:10 am |2.4
|!1:30 am |0.5
|!1:50 am |-1.2
|!2:10 am |-2.3
|!2:30 am |3.2

If you don't specify a name, it will be set to the default value =='(no name)'==:

[[[
DataSeries
  withKeys: #(temperature precipitation type)
  values: #(0.5 true rain).
]]]

| |!(no name)
|!temperature |0.5
|!precipitation |true
|!type |rain

You can also create a data series without keys, in which case they fill be filled with default values: numbers from 1 to the size of your data series:

[[[
temperature := DataSeries
  withValues: #(2.4 0.5 -1.2 -2.3 3.2)
  name: #temperature.
]]]

| |!temperature
|!1 |2.4
|!2 |0.5
|!3 |-1.2
|!4 |-2.3
|!5 |3.2

Or only with values:

[[[
DataSeries
  withValues: #(2.4 0.5 -1.2 -2.3 3.2).
]]]

| |!(no name)
|!1 |2.4
|!2 |0.5
|!3 |-1.2
|!4 |-2.3
|!5 |3.2

That last expression has a shorter form which produces the same result:

[[[
#(2.4 0.5 -1.2 -2.3 3.2) asDataSeries.
]]]

!!! Discovering data series API

==DataSeries== is an extended ==OrderedDictionary==. It combines the API of both ==Dictionary== and ==SequenceableCollection==, and adds some additional functionality that can be useful for data analysis. This simple data structure does not require a long introduction but it is still worth to demonstrate how it can be used. In this section, I briefly cover the public API of a ==DataSeries== class and describe the additional methods that are not present in other Pharo collections.

!!!! Accessing and modifying values

In this aspect, ==DataSeries== acts like an ==OrderedDictionary==. You can access an element at a certain key using ==at: aKey== message, you can modify this element with ==at: aKey put: newValue==. To remove an element, use ==removeAt: aKey==. If ==aKey== is not present in the data series, a new element will be created and added to the end. Alternatively, you can use methods such as ==at: ifAbsent:==, ==at: ifAbsentPut:==, etc. to provide custom block that will be evaluated when ==aKey== is not found.

You can also access elements by their index rather than key with methods ==atIndex:==, ==atIndex: put:==, and ==removeAtIndex:==.

Here is the list of some accessors provided by ==DataSeries==. This list is incomplete. Many other accessors are inherited from ==OrderedCollection== class. They can come in handy but we do not discuss them in this booklet:

[[[
DataSeries >> at:
DataSeries >> at: ifAbsent:
DataSeries >> at: put:
DataSeries >> removeAt:
DataSeries >> atIndex:
DataSeries >> atIndex: put:
DataSeries >> removeAtIndex:
]]]

Now we present the non traditional and powerful API of ==DataSeries==.

!!! at:transform:
@secAtTransform

==DataSeries== provides additional set of ==at: transform:== modifying accessors. Consider a situation when you want to convert a certain value of the temperature data series from Celsius to Fahrenheit. Having to specify key twice we make the whole expression long and hard to comprehend:

[[[
temperature at: '01:30' asTime put: (temperature at: '01:30' asTime)  * 9/5 + 32.
]]]

And since operations on data series (rows and columns) are the building block of most data frame queries, we want them to be as short and readable as possible. To simplify complex queries, ==DataSeries== provides a set of methods that allow you to transform an element at certain position using a block:

[[[
DataSeries >> at: transform:
DataSeries >> at: transform: ifAbsent:
DataSeries >> atIndex: transform:
]]]

We can now rewrite the above expression as

[[[
temperature at: '01:30' asTime transform: [ :x | x * 9/5 + 32 ].
]]]

!!! Enumerating values of data series
@secEnumeratingSeries

As a combination of ==Dictionary== and ==SequenceableCollection==, ==DataSeries== understands the following methods for enumerating its values:

|!Value |!Value and key |!Value and index
|do: |withKeyDo: |withIndexDo:
|select: |withKeySelect: |withIndexSelect:
|reject: |withKeyReject: |withIndexReject:
|collect: |withKeyCollect: |withIndexCollect:
|detect: |withKeyDetect: |withIndexDetect:
|detect: ifNone: |withKeyDetect: ifNone: |withIndexDetect: ifNone:
|inject: into: |- |-

For example, we can collect the Fahrenheit values of ==temperature== into a separate series:

[[[
fahrenheit := temperature collect: [ :x | x * 9/5 + 32 ].
]]]

| |!temperature
|!1 |36.32
|!2 |32.9
|!3 |29.84
|!4 |27.86
|!5 |37.76

Notice that the name of this data series is still ==temperature==, because that was the name of a series from which the values were collected, and no other name was provided by the ==collect:== message. If needed, you can rename the ==fahrenheit== series later:

[[[
fahrenheit name: #fahrenheit.
]]]

To see another example of enumerating values of data series, let's now find the first value of the ==fahrenheit== series that is below 32 (zero on Celsius scale):

[[[
fahrenheit detect: [ :x | x < 32 ].
]]]

The answer will be ==29.84== - the third element of our series.

!!! Arithmetical operations

Similarly to other collections in Pharo, ==DataSeries== responds to basic arithmetical operations, such as ==+, -, *, /==. You can apply these operations on any of the following combinations: series-series, series-scalar, or scalar-series (although, the last one is not supported for division).

In order to demonstrate the application of arithmetical operations, let's create two simple data series filled with numbers:

[[[
a := DataSeries withValues: #(0.5 2 -1 0) name: #a.
b := DataSeries withValues: #(-2 -0.5 1 3) name: #b.
]]]

When an operation is applied to a scalar and a series, it is performed on every element of a series with the given scalar. For example, if you divid data series ==a== by 2, each of its elements will be divided by 2:

[[[
a / 2.
]]]

| |!a
|!1 |0.25
|!2 |1
|!3 |-0.5
|!4 |0

Similarly, if you subtract data series ==b== from the number 1, you will get a new series, in which each element is the difference between 1 and the corresponding element of series ==b==:

[[[
1 - b.
]]]

| |!b
|!1 |3
|!2 |1.5
|!3 |0
|!4 |-2

When the operation is applied to a pair of two data series, it will be performed in the elementwise manner. So, for example, if you want to add two data series ==a== and ==b==, you will get a third series where first element is the sum of the first elements of ==a== and ==b==, second element is the sum of second elements, etc. In this case, both data series must be of the same size and must have same keys. The name of the resulting series will be the same as the name of the first operand:

[[[
a + b.
]]]

| |!a
|!1 |-1.5
|!2 |1.5
|!3 |0
|!4 |3

In fact, the conversion of ==temperature== series to Fahrenheit scale, that was demonstrated earlier in Section *@secEnumeratingSeries* with ==collect:== message, can be done directly by applying arithmetical operations to the data series:

[[[
fahrenheit := temperature * 9/5 + 32.
]]]

The result will be the same as before.

!!! Some useful mathematical functions

Although, you can apply any operation to the elements of your series using ==collect:==, sometimes your code will be more readable if you send a message to the whole data series and expect it to be performed on all its elements. In the same way as when we add 1 to a data series and get a new series with all elements of the first series incremented by 1, we also want to say ==series exp== and expect a data series of exponents.

Here is the list of mathematical operations that are understood by ==DataSeries== and can be performed in the elementwise manner:

[[[
DataSeries >> abs
DataSeries >> cos
DataSeries >> sin
DataSeries >> tan
DataSeries >> exp
DataSeries >> ln
DataSeries >> log
DataSeries >> log:
DataSeries >> sqrt
DataSeries >> **
]]]

The last one is the binary operator which takes data series as the first operand and raises all its elements to the power of second operand.

Let's find the exponent and the natural logarithm of the temperature series:

[[[
temperature exp.
]]]

| |!temperature
|!1 |11.02
|!2 |1.65
|!3 |0.3
|!4 |0.1
|!5 |24.53

As we take the natural logarithm, the third and fourth elements in the resulting data series are ==Float nan== because logarithms are only defined for positive numbers and those two temperatures are below zero:

[[[
temperature ln.
]]]

| |!temperature
|!1 |0.88
|!2 |-0.69
|!3 |Float nan
|!4 |Float nan
|!5 |1.16

@@note Unlike most other programming languages and libraries for numerical coomputations that define ==log== as natural logarithm, Pharo defines it as a logarithm with base 10. Natural logarithm is defined as ==ln==. And parametrised message ==log:== can be used to get a logarithm with any other base, for example: ==(1024 log: 2) = 10.0==.

!!! Statistical operations

In addition to statistical methods understood by all collections, such as ==average==, ==min==, or ==max==, ==DataSeries== class provides methods more advanced methods that are commonly used when analysing quantitative columns. Here is the complete list of statistical methods understood by ==DataSeries==:

[[[
DataSeries >> min
DataSeries >> max
DataSeries >> range
DataSeries >> average
DataSeries >> median
DataSeries >> mode
DataSeries >> quantile:
DataSeries >> quartile:
DataSeries >> zerothQuartile
DataSeries >> firstQuartile
DataSeries >> secondQuartile
DataSeries >> thirdQuartile
DataSeries >> fourthQuartile
DataSeries >> interquartileRange
]]]

If any of these methods is applied to a non-numerical data series, it will signal an exception.

To demonstrate the application of statistical methods, let's find average, median, standard deviation, and variance of the temperature column:

[[[
temperature average. "0.52"
temperature median. "0.5"
temperature stdev. "2.3253"
temperature variance. "5.407"
]]]

We can also check if the following equalities hold: zeroth quartile should be the same as min, fourth quartile should be the same as max, second quartile - same as median, interquartile range equals third quartile minus the first one, range is max minus min, and variance is the square of standard deviation:

[[[
temperature zerothQuartile = temperature min. "true"
temperature fourthQuartile = temperature max. "true"
temperature secondQuartile = temperature median. "true"
temperature interquartileRange = (temperature thirdQuartile - temperature firstQuartile). "true"
temperature range = (temperature max - temperature min). "true"
temperature variance = (temperature stdev ** 2). "true"
]]]

!!!! Summarizing a DataSeries

You can get a quick summary of the distribution of a numerical data series as a collection of its minimal and maximal values, first and third quartiles, average value, and a median.

Let's see how it works for the temperature series created in *@secCreatingDataSeries*:

[[[
temperature summary.
]]]

| |!temperature
|!Min |-2.3
|!1st Qu. |-1.2
|!Median |0.5
|!Average |0.52
|!3rd Qu. |2.4
|!Max |3.2

!!! Working with categorical values

Categorical data series have a fixed dictionary of values. For example, series ==sex== which has values ==Male== and ==Female==, boolean series with values ==true== and ==false==, series with sizes of clothes: ==XS==, ==S==, ==M==, ==L==, ==XL==, etc. We can not perform mathematical and statistical operations on categorical series (except for ==mode==, which only finds the most common value), however there is still a lot of ways to analyse such data. In the rest of this section, I will show you several methods of ==DataSeries== that are especially useful for working with categorical values. The examples will be based on the ==precipitation== and ==type== columns of weather dataset. I remind you how they are created:

[[[
keys := #('01:10' '01:30' '01:50' '02:10' '02:30') collect: #asTime.

precipitation := DataSeries
  withKeys: keys
  values: #(true true true false true)
  name: #precipitation.

type := DataSeries
  withKeys: keys
  values: #(rain rain snow - rain)
  name: #type.
]]]

!!!! uniqueValues

The most basic operation that can be performed is finding the unique values of the series:

[[[
precipitation uniqueValues. "#(false true)"
type uniqueValues. "#(- rain snow)"
]]]

This allows us to see the complete dictionary of values used in a data series.

!!!! valueCounts

Another thing you might want to know is how the values of your categorical data series are distributed. How many times did it rain, according to your dataset? How many times did it snow? ==valueCounts== method will give you the counts of unique values in your data series:

[[[
type valueCounts.
]]]

| |!type
|!rain |3
|!snow |1
|!- |1

The result will be a data series with unique values as keys and counts as values. It will be sorted by counts in the descending order.

!!!! valueFrequencies

Sometimes, instead of counts, you want to see the relative frequencies of the unique values in your data series:

[[[
type valueFrequencies.
]]]

| |!type
|!rain |(3/5)
|!snow |(1/5)
|!- |(1/5)

In fact, it is the same as dividing value counts by the size of your series:

[[[
type valueFrequencies = (type valueCounts / type size). "true"
]]]

!!!! crossTabulateWith:

Cross tabulation is a powerful way to analyse the correlation between two categorical series. It creates a table with rows corresponding to the unique values of the first series, columns corresponding to the unique values of second series, and each cell containing the count of those value pairs.

By cross tabulating ==precipitation== series with ==type== series, we can see that they are closely correlated - when ==precipitation== is ==false==, the ==type== is always empty, and when ==precipitation== is ==true==, the ==type== is either ==rain== or ==snow==:

[[[
precipitation crossTabulateWith: type.
]]]

The result will be the data frame of cross tabulated values:

| |!snow |!rain |!-
|!false |0 |0 |1
|!true |1 |3 |0

!!! Creating a data frame

In this section, we will look at different ways of creating the weather data frame described in Section *@weatherDataset*.
You will also learn to create empty data frames that can be filled with values later.

!!!! Initializing a data frame with an array of rows

The most basic way to initialize a data frame is with an array (or any other ordered collection) of rows where each row is a collection of elements. Let's create the weather data frame from its rows:

[[[
weather := DataFrame withRows: #(
	(2.4 true rain)
	(0.5 true rain)
	(-1.2 true snow)
	(-2.3 false -)
	(3.2 true rain)).
]]]

!!!! Initializing a data frame with an array of columns

Alternatively, you can create a data frame by passing it a collection of columns. This can be handy, for example, when engineering new features: ==DataFrame withColumns: { income . income ** 2 . income log }==. In our case, we create the same weather data frame:

[[[
weather := DataFrame withColumns: #(
  (2.4 0.5 -1.2 -2.3 3.2)
  (true true true false true)
  (rain rain snow - rain)).
]]]

!!!! Specifying column and row names

Both expressions in two previous sections create the same data frame.

| |!1 |!2 |!3
|!1 |2.4 |true |rain
|!2 |0.5 |true |rain
|!3 |-1.2 |true |snow
|!4 |-2.3 |false |-
|!5 |3.2 |true |rain

Since the names of rows and columns were not specified, they were initialized with their default values: ==(1 to: self numberOfRows)== and ==(1 to: self numberOfColumns)==. We can provide more meaningful names:

[[[
weather := DataFrame withColumns: #(
  (2.4 0.5 -1.2 -2.3 3.2)
  (true true true false true)
  (rain rain snow - rain)).

weather columnNames: #(temperature precipitation type).
weather rowNames: (#('01:10' '01:30' '01:50' '02:10' '02:30')
		collect: #asTime).
]]]

I would like to emphasize that names don't have to be strings or numbers. They can be any objects, and in this case they are instances of Time. Now the data frame looks the same as the table in Figure *@weatherDataFrame* (A).

| |!temperature |!precipitation |!type
|!1:10 am |2.4 |true |rain
|!1:30 am |0.5 |true |rain
|!1:50 am |-1.2 |true |snow
|!2:10 am |-2.3 |false |-
|!2:30 am |3.2 |true |rain

!!!! Compact methods for initializing data frames

==DataFrame== class provides syntactic sugar that allows us to initialize it with contents and (optionally) row and column names in a single line. Here is the complete list of those initializers:

[[[
DataFrame class >> withRows: columnNames:
DataFrame class >> withRows: rowNames:
DataFrame class >> withRows: rowNames: columnNames:
DataFrame class >> withColumns: columnNames:
DataFrame class >> withColumns: rowNames:
DataFrame class >> withColumns: rowNames: columnNames:
]]]

Whenever row or column names are not specified, they are initialized with their default values.

!!! Creating empty data frames

Sometimes we need to create an empty data frame that will be filled with data later on. The easiest way of doing this is with

[[[
DataFrame new. "empty data frame with 0 rows and 0 columns"
]]]

This will create an empty data frame with no columns and rows. You can also create an empty data frame of a given size by specifying it as a point ==numberOfRows @ numberOfColumns==. All cells of such data frame will be empty (initialized with ==nil==).

[[[
DataFrame new: 3@4. "empty data frame with 3 rows and 4 columns"
]]]

Similarly to the syntactic sugar described in the previous section, DataFrame class has methods that allow us to create data frames by specifying only their rows, columns, or both. Since we do not provide any data, such data frames with be empty and their sizes will correspond to the provided arrays of rows and columns. For example, if you create an empty data frame with columns ==#(temperature precipitation type)==, its size will be ==0@3==. Here are the methods that can be used to create an empty data frame with names:

[[[
DataFrame class >> withRowNames:
DataFrame class >> withColumnNames:
DataFrame class >> withRowNames: columnNames:
]]]

For example, we can initialize an empty weather data frame:

[[[
emptyWeather := DataFrame
  withRowNames: (#('01:10' '01:30' '01:50' '02:10' '02:30') collect: #asTime)
  columnNames: #(temperature precipitation type).
]]]

| |!temperature |!precipitation |!type
|!1:10 am |nil |nil |nil
|!1:30 am |nil |nil |nil
|!1:50 am |nil |nil |nil
|!2:10 am |nil |nil |nil
|!2:30 am |nil |nil |nil

@@note Although it is possible to create a data frame with no rows using ==DataFrame class >> new== or ==DataFrame >> withColumnNames:== and add rows later by pushing them one by one, this is not recommended. DataFrame is not optimized for the insertion of new elements. It may be more efficient to first add rows into an OrderedCollection and then initialize a data frame with it.

!!! Inspecting a data frame

It is hard to work with data tables without being able to see them. Fortunately, Pharo environment provides a powerful inspector which allows you examine live objects and even modify them. If you inspect a data frame object (select it anywhere in the code and press Ctrl\+I or Ctrl\+G if you are in Playground), you will see the table similar to the one in Figure *@inspector*.

+Inspecting weather data frame >Images/fastTableWhite.png|width=100|label=inspector+

!!! Accessing parameters of data frame

Data frames are defined by their contents (table of data), as well as their column and row names. For the simplicity, we provide access to some additional parameters such as the dimensions of a data frame. In the following sections, we will discuss how to access row and columns, as well as its individual cells. In this section, I will show you how to get other parameters such as names or sizes.

!!!! Dimensions

Getting the number of rows and columns of a data frame is straightforward:

[[[
weather numberOfRows. "5"
weather numberOfColumns. "3"
]]]

You can also get both dimensions of a data frame as a ==Point==:

[[[
weather dimensions. "5@3"
]]]

!!!! Row and column names

Every data frame has names associated to its rows and columns (either used-defined or auto-generated). These names can be used for referencing specific rows or columns (which you will learn in Section *@secAccessingByName*). Let's get the collection of all row and column names of a weather data frame:

[[[
weather rowNames.
weather columnNames.
]]]

!!!! Transposed DataFrame

Sometimes it is useful to transpose a data frame made out of columns and rows into rows and columns. To do that, you can simply write

[[[
weather transposed
]]]

The result will be a new data frame which looks like this:

| |!1:10 am |!1:30 am |!1:50 am |!2:10 am |!2:30 am
|!temperature |2.4 |0.5 |-1.2 |-2.3 |3.2
|!precipitation |true |true |true |false |true
|!type |rain |rain |snow |- |rain

!!! Accessing rows and columns

In this section, I will show you how to get the values of specific rows and columns, as well as how to modify these values. Rows and columns of a data frame can be accessed either by their names or their numeric indexes.

!!!! Accessing by name
@secAccessingByName

You can get row ==01:50== and the column ==temperature== of the weather data frame by writing:

[[[
weather row: '01:50' asTime.
weather column: #temperature.
]]]

Use methods ==row: put:== and ==column: put:== to modify the values stored in a row or column:

[[[
weather row: '01:50' asTime put: #(10 true rain).
weather column: #temperature put: #(1.2 -2.1 3.4 -5.9 -0.4).
]]]

| |!temperature |!precipitation |!type
|!1:10 am |1.2 |true |rain
|!1:30 am |-2.1 |true |rain
|!1:50 am |3.4 |true |rain
|!2:10 am |-5.9 |false |-
|!2:30 am |-0.4 |true |rain

If you reference a row or column by a non-existing name you will get the ==NotFoundError== and if the array you provide is too big or too small, the ==SizeMismatch== error will be signaled. Notice that you can not add a new column using ==dataFrame column: #newName put newArray==. This is done with ==addColumn:== set of methods that will be described in the following sections.

!!!! Accessing by index

Rows and columns can also be accessed by their numeric indices. You can get the same row and column as in the previous example using

[[[
weather rowAt: 3.
weather columnAt: 1.
]]]

To modify them, use ==rowAt: put:== and ==columnAt: put:==.

[[[
weather rowAt: 3 put: #(-1.2 true snow).
weather columnAt: 1 put: #(2.4 0.5 -1.2 -2.3 3.2).
]]]

| |!temperature |!precipitation |!type
|!1:10 am |2.4 |true |rain
|!1:30 am |0.5 |true |rain
|!1:50 am |-1.2 |true |snow
|!2:10 am |-2.3 |false |-
|!2:30 am |3.2 |true |rain

!!!! Accessing multiple rows and columns

To access multiple rows or columns at a same time, you have to provide an array of names or indices, or specify the range of indices. In the following example, we get the three middle rows of the weather data frame:

[[[
weather rows: { '01:30' asTime . '01:50' asTime . '02:10' asTime}.
weather rowsAt: #(2 3 4).
weather rowsFrom: 2 to: 4.
]]]

The same can be done to access, for example, the last two columns:

[[[
weather columns: #(precipitation type).
weather columnsAt: #(2 3).
weather columnsFrom: 2 to: 3.
]]]

The result will be another data frame with only the requested rows or columns in the order in which you ask for them. This means that you can ask for rows 3, 2, and the 5 or column ==precipitation== followed by the ==temperature==:

[[[
weather rowsAt: #(3 2 5).
weather columns: #(precipitation temperature).
]]]

All the above methods can be used together with ==put:== to replace the given rows or columns with new ones:

[[[
DataFrame >> rows: put:
DataFrame >> rowsAt: put:
DataFrame >> rowsFrom: to: put:
DataFrame >> columns: put:
DataFrame >> columnsAt: put:
DataFrame >> columnsFrom: to: put:
]]]

!!!! Head and Tail

To understand the nature of a dataset with 100,000 rows, it helps if we can take a look at its first or last 5 rows. This is called the ""head"" or ""tail"" of a dataset. ==DataFrame== allows you to get the arbitrary number of rows at its beginning or end using ==head: aNumber== and ==tail: aNumber== methods. It also provides simpler methods ==head== and ==tail== which return 5 rows by default.

For example, if we want to get the first 2 rows from our weather data frame:

[[[
weather head: 2.
]]]

| |!temperature |!precipitation |!type
|!1:10 am |2.4 |true |rain
|!1:30 am |0.5 |true |rain

Or the tail with the last 3 rows:

[[[
weather tail: 2.
]]]

| |!temperature |!precipitation |!type
|!1:50 am |-1.2 |true |snow
|!2:10 am |-2.3 |false |-
|!2:30 am |3.2 |true |rain

Both ==head== and ==tail== are returned to you as new data frames with only the corresponding rows. DataSeries also implements the ==head==/==tail== methods, which allows you to get the ==head== or ==tail== of a single row or column as a new data series with only the first or last elements

[[[
(weather column: #temperature) head: 2.
]]]

| |!temperature
|!1:10 am |2.4
|!1:30 am |0.5

!!! Adding rows and columns
@secAddingRowsAndColumns

You can add new rows and columns to data frame by providing an array of values a name of the new row or column, and its position as an index:

[[[
weather
  addColumn: #(86 79 23 16 90)
  named: #humidity
  atPosition: 2.
]]]

The above statement will modify the weather dataset by adding a humidity column to it right after the temperature column:

| |!temperature |!humidity |!precipitation |!type
|!1:10 am |2.4 |86 |true |rain
|!1:30 am |0.5 |79 |true |rain
|!1:50 am |-1.2 |23 |true |snow
|!2:10 am |-2.3 |16 |false |-
|!2:30 am |3.2 |90 |true |rain

You can omit the position using methods ==addRow:named:== or ==addColumn:named:==. By default rows and columns will be added to the end of data frame:

[[[
weather
  addRow: #(2.0 81 true rain)
  named: '2:50' asTime.
]]]

| |!temperature |!humidity |!precipitation |!type
|!1:10 am |2.4 |86 |true |rain
|!1:30 am |0.5 |79 |true |rain
|!1:50 am |-1.2 |23 |true |snow
|!2:10 am |-2.3 |16 |false |-
|!2:30 am |3.2 |90 |true |rain
|!2:50 am |2.0 |81 |true |rain

Alternatively, you can add new rows or columns as data series. In this case you do not need to provide a name because the data series already knows its name.

[[[
wind := DataSeries
  withValues: #(39 39 32 24 14 14)
  name: #wind.

weather
  addColumn: wind
  atPosition: 2.
]]]

Notice that we did not specify the keys of the data series with wind measurements. It was initialized with default keys. When adding new row or column as a data series, ==DataFrame== does not take keys into account.

| |!temperature |!wind |!humidity |!precipitation |!type
|!1:10 am |2.4 |39 |86 |true |rain
|!1:30 am |0.5 |39 |79 |true |rain
|!1:50 am |-1.2 |32 |23 |true |snow
|!2:10 am |-2.3 |24 |16 |false |-
|!2:30 am |3.2 |14 |90 |true |rain
|!2:50 am |2.0 |14 |81 |true |rain

You can use ==addRow:== or ==addColumn:== without specifying the position, in which case the new row or column will be added to the end.

Just as before, when we were modifying the existing rows and columns, if you try to add new row or column which is too big or too small, ==DataFrame== will signal a ==SizeMismatch== error.

!!! Removing rows and columns

To remove a row or column from a data frame, you have to provide either its name or index. In the previous section we have added two columns and one row to the data frame. Now we can remove the ==wind== column and the last row that was added:

[[[
weather removeColumn: #wind.
weather removeRowAt: 6.
]]]

This gives us the same weather dataset as we had at the beginning with an additional ==humidity== column.

| |!temperature |!humidity |!precipitation |!type
|!1:10 am |2.4 |86 |true |rain
|!1:30 am |0.5 |79 |true |rain
|!1:50 am |-1.2 |23 |true |snow
|!2:10 am |-2.3 |16 |false |-
|!2:30 am |3.2 |90 |true |rain

If you try to remove a column or row by a name which does not exist or by index that is out of range, you will get the ==NotFoundError== or ==SubscriptOutOfBounds==.

!!! Enumerating rows of data frame

==DataFrame== can be treated as an array of rows. You can enumerate them in the same way as you enumerate any other sequenceable collection in Smalltalk: ==do:==, ==collect:==, ==select:==, ==reject:==, and ==inject:into:==.

!!!! do: aBlock

Evaluate ==aBlock== for each row of the receiver data frame. Let us convert the temperatures from Celsius to Fahrenheit:

[[[
weather do: [ :row |
  row at: #temperature transform: [ :celsius |
    celsius * 9/5 + 32 ] ].
]]]

| |!temperature |!humidity |!precipitation |!type
|!1:10 am |36.32 |86 |true |rain
|!1:30 am |32.9 |79 |true |rain
|!1:50 am |29.84 |23 |true |snow
|!2:10 am |27.86 |16 |false |-
|!2:30 am |37.76 |90 |true |rain

!!!! select: aBlock

Evaluate ==aBlock== for each row of the receiver data frame. Collect into a new data frame only those rows for which ==aBlock== evaluates to ==true==. Answer the new data frame. We can select the records that are below the freezing temperature:

[[[
weather select: [ :row |
  (row at: #temperature) < 32 ].
]]]

| |!temperature |!humidity |!precipitation |!type
|!1:50 am |29.84 |23 |true |snow
|!2:10 am |27.86 |16 |false |-

!!!! reject: aBlock

Evaluate ==aBlock== for each row of the receiver data frame. Collect into a new data frame only those rows for which ==aBlock== evaluates to ==false==. Answer the new data frame. Now if we reject the freezing temperatures, we will get all other records.

[[[
weather reject: [ :row |
  (row at: #temperature) < 32 ].
]]]

| |!temperature |!humidity |!precipitation |!type
|!1:10 am |36.32 |86 |true |rain
|!1:30 am |32.9 |79 |true |rain
|!2:30 am |37.76 |90 |true |rain

!!!! collect: aBlock

Evaluate ==aBlock== for each row of the receiver data frame. Collect into a new data frame the rows that were answered by ==aBlock==. Therefore, ==aBlock== is expected to return a data series of certain size. This size can be different than the number of columns in the original data frame, but the same for every answered row. Keys of the answered data series will be set as column names of the new data frame. For example, we can collect rows of weather data frame into a new data frame with the values of ==humidity== column converted to the 0-1 scale and with ==precipitation== column removed:

[[[
weather collect: [ :row |
  row at: #humidity transform: [ :percent | percent / 100 ].
  row removeAt: #precipitation.
  row ].
]]]

The result will be a new data frame:

| |!temperature |!humidity |!type
|!1:10 am |36.32 |0.86 |rain
|!1:30 am |32.9 |0.79 |rain
|!1:50 am |29.84 |0.23 |snow
|!2:10 am |27.86 |0.16 |-
|!2:30 am |37.76 |0.9 |rain

Remember that the original weather data frame is not modified.

!!!! detect: aBlock

Evaluate ==aBlock== for each row of the receiver data frame. Answer the first row for which ==aBlock== evaluates to ==true==. If none evaluates to ==true==, report an error. For example, we can detect the first row with a freezing temperature:

[[[
weather detect: [ :row |
  (row at: #temperature) < 32 ].
]]]

| |!1:50 am
|!temperature |29.84
|!humidity |23
|!precipitation |true
|!type |snow

!!!! detect: aBlock ifNone: exceptionBlock

Evaluate ==aBlock== for each row of the receiver data frame. Answer the first row for which ==aBlock== evaluates to ==true==. If none evaluates to ==true==, evaluate ==exceptionBlock== which must be a block requiring no arguments. For example, since weather dataset does not contain any observations (rows) with temperatures lower than 20, the following expression will evaluate to the ''not found'' string:

[[[
weather
  detect: [ :row | (row at: #temperature) < 20 ]
  ifNone: [ 'not found' ].
]]]

!!!! inject: thisValue into: binaryBlock

Evaluate ==binaryBlock== once for each row in the receiver data frame. The block has two arguments: the second one is the row from the receiver; the first one is the is the value of the previous evaluation of the block, starting the argument ==thisValue==. Answer the final value of a block.

We can use it to sum up all values of the two numeric columns: ==temperature== and ==humidity==:

[[[
(weather columns: #(temperature humidity))
	inject: 0
	into: [ :sum :row | sum + row ].
]]]

| |!(no name)
|!temperature |164.68
|!humidity |294

Additionally, ==DataFrame== provides special methods for enumerating it with row index. The following table lists all enumeration methods understood by ==DataFrame==:

|!Row |!Row and index
|do: |withIndexDo:
|select: |withIndexSelect:
|reject: |withIndexReject:
|collect: |withIndexCollect:
|detect: |-
|detect: ifNone: |-
|inject: into: |-

We do not need to enumerate rows with their names because each row is a data series which already knows its name.

!!! Aggregation and Grouping

Aggregation and grouping is among the most used operations in data analysis workflow. It allows us to first group rows of a data frame by a value of some column and then aggregate each one of these groups into a single value with some function or block, for example, ==average==, ==sum==, etc.

Let's ask weather data frame to answer the following question: ''"What is the average temperature when it rains, snows, or when there is no precipitation?"''. To do that, we group the values of ==temperature== column by the ==type== column and find the average value of each group.

[[[
weather
	group: #temperature
	by: #type
	aggregateUsing: #average
  as: #averageTemperature.
]]]

This gives us a data series of average temperatures by precipitation type called ==averageTemperature==:

| |!averageTemperature
|!- |27.86
|!rain |35.66
|!snow |29.84

You can omit the ==as: #averageTemperature== part of that message, in which case the answered data series will have the same name as the column that was aggregated: ==temperature==.

Values of data series are grouped into a data series of groups where each group is also a data series. Aggregation function or block is then applied to each one of these groups. Which means that aggregation function can be any selector understood by ==DataSeries==. And the result of aggregation and grouping expression will be a data series of answers from your aggregation function or block (which can be scalar values or collections).

Let's look at the total number of rows, lowest and highest temperature values, and average humidity in each group:

[[[
weather
  groupBy: #type
  aggregate: {
    #temperature using: #size as: #count .
    #temperature using: #min as: #minTemperature .
    #temperature using: #max as: #maxTemperature .
    #humidity using: #average as: #avgHumidity }.
]]]

Notice that ==count== column is constructed by aggregating groups of ==temperature== with ==#size== message. In fact, any column can be used in place of ==temperature==.

| |!count |!minTemperature |!maxTemperature |!avgHumidity
|!- |1 |27.86 |27.86 |16
|!rain |3 |32.9 |37.76 |85
|!snow |1 |29.84 |29.84 |23

!!! Reading from and writing to files

In practice, data frames are useful when you can load some data from an external source into a data frame, modify and analyse it, then save result. External source can be a CSV or Excel file, a database connection, or any other source of data In this section I will describe the ==DataFrame-IO== package of the ==DataFrame project== which allows you to load and save data frames.

==DataFrame-IO== provides two abstract classes: ==DataFrameReader== and ==DataFrameWriter==. Each of them has only one abstract method: ==DataFrameReader >> readFrom: aLocation== (expected to return a data frame) and ==DataFrameWriter >> write: aDataFrame to: aLocation==.
To add support for some external data source, you need to override those methods in your subclasses, providing the actual algorithm for reading and writing data. ==DataFrame== has two methods that allow you to read or write it using your reader or writer:

[[[
DataFrame class >> readFrom: aLocation using: aDataFrameReader
  "Read data frame from a given location using a given DataFrameReader. Location can be a file reference, a database connection, or something else (depending on the implementation of the reader)"
  ^ aDataFrameReader readFrom: aLocation
]]]
[[[
DataFrame >> writeTo: aLocation using: aDataFrameWriter
  "Write data frame to a given location using a given DataFrameWriter. Location can be a file reference, a database connection, or something else (depending on the implementation of the writer)"
  aDataFrameWriter write: self to: aLocation
]]]

!!!! CSV support

""CSV"" (comma-separated values) is the file format that is most commonly used by data scientists to save and share tabular data. It is a simple text file in which each row is written on the new line and values of a row are separated by commas. You can use other character as separator instead of comma, for example, one common choice is tabulation.

==DataFrame-IO== package comes with two subclasses of ==DataFrameReader== and ==DataFrameWriter==: ==DataFrameCsvReader== and ==DataFrameCsvWriter==. They override ==readFrom:== and ==write:to:== methods using ==NeoCSV== ${footnote:note=https://github.com/svenvc/NeoCSV}$ and allow you to make optional configurations, such as specifying the separator character (comma by default) or line end convention (either ==#cr==, ==#lf==, or ==#crlf==, by default we choose the one used by your OS). By default, ==DataFrameCsvReader== will read all columns of the CSV file as data frame columns and assign the default names to rows - numbers from 1 to ==numberOfRows==. However, you can configure it to read first column as row names by sending ==true== to the ==DataFrameCsvReader >> includeRowNames:==. In this case ==aLocation== parameter of ==readFrom:== and ==write:to:== methods is expected to be a ==FileReference==.

Because reading and writing CSV files is very common in data analysis workflow, ==DataFrame== provides shortcuts for these methods:

[[[
DataFrame class >> readFromCsv:
DataFrame class >> readFromCsv: withSeparator:
DataFrame class >> readFromCsvWithRowNames:
DataFrame class >> readFromCsvWithRowNames: separator:
DataFrame >> writeToCsv:
DataFrame >> writeToCsv: withSeparator:
]]]

!!! Conclusion

This chapter has guided you through the complete functionality of the ==DataFrame== project. It offered you examples of different methods without any logical connection between them. In the following chapters you will find short tutorials which demonstrate the application of data frames to real life problems.
